import { Anthropic } from "@anthropic-ai/sdk";
import * as vscode from "vscode";
import { type ModelInfo } from "@roo-code/types";
import type { ApiHandlerOptions } from "../../shared/api";
import { ApiStream } from "../transform/stream";
import { BaseProvider } from "./base-provider";
import type { SingleCompletionHandler, ApiHandlerCreateMessageMetadata } from "../index";
/**
 * Handles interaction with VS Code's Language Model API for chat-based operations.
 * This handler extends BaseProvider to provide VS Code LM specific functionality.
 *
 * @extends {BaseProvider}
 *
 * @remarks
 * The handler manages a VS Code language model chat client and provides methods to:
 * - Create and manage chat client instances
 * - Stream messages using VS Code's Language Model API
 * - Retrieve model information
 *
 * @example
 * ```typescript
 * const options = {
 *   vsCodeLmModelSelector: { vendor: "copilot", family: "gpt-4" }
 * };
 * const handler = new VsCodeLmHandler(options);
 *
 * // Stream a conversation
 * const systemPrompt = "You are a helpful assistant";
 * const messages = [{ role: "user", content: "Hello!" }];
 * for await (const chunk of handler.createMessage(systemPrompt, messages)) {
 *   console.log(chunk);
 * }
 * ```
 */
export declare class VsCodeLmHandler extends BaseProvider implements SingleCompletionHandler {
    protected options: ApiHandlerOptions;
    private client;
    private disposable;
    private currentRequestCancellation;
    constructor(options: ApiHandlerOptions);
    /**
     * Initializes the VS Code Language Model client.
     * This method is called during the constructor to set up the client.
     * This useful when the client is not created yet and call getModel() before the client is created.
     * @returns Promise<void>
     * @throws Error when client initialization fails
     */
    initializeClient(): Promise<void>;
    /**
     * Creates a language model chat client based on the provided selector.
     *
     * @param selector - Selector criteria to filter language model chat instances
     * @returns Promise resolving to the first matching language model chat instance
     * @throws Error when no matching models are found with the given selector
     *
     * @example
     * const selector = { vendor: "copilot", family: "gpt-4o" };
     * const chatClient = await createClient(selector);
     */
    createClient(selector: vscode.LanguageModelChatSelector): Promise<vscode.LanguageModelChat>;
    /**
     * Creates and streams a message using the VS Code Language Model API.
     *
     * @param systemPrompt - The system prompt to initialize the conversation context
     * @param messages - An array of message parameters following the Anthropic message format
     * @param metadata - Optional metadata for the message
     *
     * @yields {ApiStream} An async generator that yields either text chunks or tool calls from the model response
     *
     * @throws {Error} When vsCodeLmModelSelector option is not provided
     * @throws {Error} When the response stream encounters an error
     *
     * @remarks
     * This method handles the initialization of the VS Code LM client if not already created,
     * converts the messages to VS Code LM format, and streams the response chunks.
     * Tool calls handling is currently a work in progress.
     */
    dispose(): void;
    /**
     * Implements the ApiHandler countTokens interface method
     * Provides token counting for Anthropic content blocks
     *
     * @param content The content blocks to count tokens for
     * @returns A promise resolving to the token count
     */
    countTokens(content: Array<Anthropic.Messages.ContentBlockParam>): Promise<number>;
    /**
     * Private implementation of token counting used internally by VsCodeLmHandler
     */
    private internalCountTokens;
    private calculateTotalInputTokens;
    private ensureCleanState;
    private getClient;
    private cleanMessageContent;
    createMessage(systemPrompt: string, messages: Anthropic.Messages.MessageParam[], metadata?: ApiHandlerCreateMessageMetadata): ApiStream;
    getModel(): {
        id: string;
        info: ModelInfo;
    };
    completePrompt(prompt: string): Promise<string>;
}
export declare function getVsCodeLmModels(): Promise<vscode.LanguageModelChat[]>;
